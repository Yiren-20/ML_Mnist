{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-06-29T13:58:02.935547Z","iopub.execute_input":"2023-06-29T13:58:02.936070Z","iopub.status.idle":"2023-06-29T13:58:02.945253Z","shell.execute_reply.started":"2023-06-29T13:58:02.935999Z","shell.execute_reply":"2023-06-29T13:58:02.944068Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"# python 3.9 \nimport random\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nfrom torch.utils.data import DataLoader, random_split\nfrom sklearn.mixture import GaussianMixture\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torchvision.transforms import ToTensor","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:02.952193Z","iopub.execute_input":"2023-06-29T13:58:02.953312Z","iopub.status.idle":"2023-06-29T13:58:02.960033Z","shell.execute_reply.started":"2023-06-29T13:58:02.953277Z","shell.execute_reply":"2023-06-29T13:58:02.959065Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"markdown","source":"数据集划分处理","metadata":{}},{"cell_type":"code","source":"# 设置随机种子\nseed = 42\ndef seed_torch(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED']= str(seed)#为了禁止hash随机化，使得实验可复现np.random.seed(seed)torch.manual_seed(seed)torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)# if you are using multi-GPU.torch.backends.cudnn.benchmark = Falsetorch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark=False\n    torch.backends.cudnn.deterministic=True\nseed_torch(seed)\ntransform = ToTensor()\n\n# 加载MNIST训练集和测试集\nmnist_train = MNIST(root='./', train=True, download=True, transform=transform)\nmnist_test = MNIST(root='./', train=False, download=True, transform=transform)\n\n# 划分训练集和验证集\ngenerator = torch.Generator().manual_seed(seed)\ntrain_dataset, val_dataset = random_split(mnist_train,[50000,10000],generator=generator)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:02.967715Z","iopub.execute_input":"2023-06-29T13:58:02.968080Z","iopub.status.idle":"2023-06-29T13:58:03.091487Z","shell.execute_reply.started":"2023-06-29T13:58:02.968052Z","shell.execute_reply":"2023-06-29T13:58:03.090477Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"markdown","source":"用kmeans划分簇","metadata":{}},{"cell_type":"code","source":"# 将MNIST数据集转换为嵌入空间\ntrain_images = [img.view(-1).numpy() for img, _ in train_dataset]\n\npca = PCA(n_components=2)\nembedded_train_images = pca.fit_transform(train_images)\n\n# 进行聚类\nkmeans = KMeans(n_clusters=10, random_state=seed)\ncluster_labels = kmeans.fit_predict(embedded_train_images)\n\n# 定义要查找的训练集图片的索引\ntarget_indices = [1173, 3336, 12529, 12785, 12979, 17351, 27048, 40579, 43128, 46498]\n\n# 找到目标索引所属的簇\ntarget_clusters = [cluster_labels[idx] for idx in target_indices]\n# 创建伪标签字典\npseudo_labels = {}\nfor i, cluster_label in enumerate(cluster_labels):\n    if cluster_label in target_clusters:\n        if cluster_label not in pseudo_labels:\n            pseudo_labels[cluster_label] = []\n        pseudo_labels[cluster_label].append(i)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:03.093456Z","iopub.execute_input":"2023-06-29T13:58:03.093895Z","iopub.status.idle":"2023-06-29T13:58:13.388950Z","shell.execute_reply.started":"2023-06-29T13:58:03.093861Z","shell.execute_reply":"2023-06-29T13:58:13.387845Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"置信度筛选","metadata":{}},{"cell_type":"code","source":"# 设置阈值\nthreshold = 0.7\n\n# 对于每个簇，筛选置信度或距离满足阈值的图片索引\nfiltered_indices = []\n\nfor cluster_label, indices in pseudo_labels.items():\n    cluster_images = [train_images[idx] for idx in indices]\n    cluster_distances = kmeans.transform(pca.transform(cluster_images))\n\n    if threshold < 1.0:\n        # 使用高斯混合模型聚类中的概率\n        confidences = np.min(cluster_distances, axis=1)\n        filtered_indices.extend([indices[i] for i, conf in enumerate(confidences) if conf > threshold])\n    else:\n        # 使用距离排名\n        sorted_indices = np.argsort(cluster_distances, axis=1)\n        num_filtered = int(len(cluster_images) * threshold)\n        filtered_indices.extend([indices[i] for i in sorted_indices[:, :num_filtered].flatten()])\n\nfinal_indices = list(set(target_indices).union(set(filtered_indices)))\n\n# 新的训练集\nnew_train_dataset = []\n\nfor idx in final_indices:\n    img, label = train_dataset[idx]\n    new_train_dataset.append((img, label))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:13.393988Z","iopub.execute_input":"2023-06-29T13:58:13.396580Z","iopub.status.idle":"2023-06-29T13:58:16.408826Z","shell.execute_reply.started":"2023-06-29T13:58:13.396543Z","shell.execute_reply":"2023-06-29T13:58:16.407564Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"markdown","source":"先处理小数据集","metadata":{}},{"cell_type":"code","source":"# 图片标签允许使用的索引\nallowed_indices = [1173, 3336, 12529, 12785, 12979, 17351, 27048, 40579, 43128, 46498]\n\n# 从训练集中筛选出允许使用的图片和标签\nfiltered_data = [(mnist_train[i][0], mnist_train[i][1]) for i in allowed_indices]\nfiltered_images, filtered_labels = zip(*filtered_data)\nfiltered_dataset = torch.utils.data.TensorDataset(torch.stack(filtered_images),\n                                                  torch.tensor(filtered_labels))\n\n# 将训练集分为训练集和验证集\ntrain_size = int(0.8 * len(filtered_dataset))\nval_size = len(filtered_dataset) - train_size\ntrain_dataset, val_dataset = random_split(filtered_dataset, [train_size, val_size])\n\n# 加载训练集、验证集和测试集\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n                          num_workers=8, persistent_workers=True)\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:16.411778Z","iopub.execute_input":"2023-06-29T13:58:16.413323Z","iopub.status.idle":"2023-06-29T13:58:16.810835Z","shell.execute_reply.started":"2023-06-29T13:58:16.413284Z","shell.execute_reply":"2023-06-29T13:58:16.809838Z"},"trusted":true},"execution_count":112,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"建立CNN模型\n","metadata":{}},{"cell_type":"code","source":"\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=2)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n        self.relu2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=2)\n        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n        self.relu3 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.relu1(x)\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = self.relu2(x)\n        x = self.pool2(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc1(x)\n        x = self.relu3(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:16.812468Z","iopub.execute_input":"2023-06-29T13:58:16.813672Z","iopub.status.idle":"2023-06-29T13:58:16.824173Z","shell.execute_reply.started":"2023-06-29T13:58:16.813635Z","shell.execute_reply":"2023-06-29T13:58:16.823046Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"markdown","source":"小数据集的训练和测试","metadata":{}},{"cell_type":"code","source":"model = CNN()\n\n# \noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ntotal_epochs = 10\n\nfor epoch in range(total_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = 100.0 * correct / total\n\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_acc = 100.0 * correct / total\n\n    print(f'Epoch {epoch+1}/{total_epochs} - Training Loss: {train_loss:.4f} - Training Acc: {train_acc:.2f}% - '\n          f'Validation Loss: {val_loss:.4f} - Validation Acc: {val_acc:.2f}%')\n    \n\n    # 在测试集上评估模型\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss /= len(test_loader)\n    test_acc = 100.0 * correct / total\n\n    print(f'Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:16.825798Z","iopub.execute_input":"2023-06-29T13:58:16.826408Z","iopub.status.idle":"2023-06-29T13:58:29.746635Z","shell.execute_reply.started":"2023-06-29T13:58:16.826373Z","shell.execute_reply":"2023-06-29T13:58:29.744971Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Epoch 1/10 - Training Loss: 2.2942 - Training Acc: 0.00% - Validation Loss: 2.3231 - Validation Acc: 0.00%\nTest Loss: 2.3061 - Test Acc: 10.09%\nEpoch 2/10 - Training Loss: 2.2272 - Training Acc: 25.00% - Validation Loss: 2.3520 - Validation Acc: 0.00%\nTest Loss: 2.3087 - Test Acc: 10.09%\nEpoch 3/10 - Training Loss: 2.1688 - Training Acc: 25.00% - Validation Loss: 2.3917 - Validation Acc: 0.00%\nTest Loss: 2.3183 - Test Acc: 10.09%\nEpoch 4/10 - Training Loss: 2.0977 - Training Acc: 25.00% - Validation Loss: 2.4539 - Validation Acc: 0.00%\nTest Loss: 2.3402 - Test Acc: 10.09%\nEpoch 5/10 - Training Loss: 2.0195 - Training Acc: 25.00% - Validation Loss: 2.5374 - Validation Acc: 0.00%\nTest Loss: 2.3805 - Test Acc: 10.09%\nEpoch 6/10 - Training Loss: 1.9360 - Training Acc: 25.00% - Validation Loss: 2.6530 - Validation Acc: 0.00%\nTest Loss: 2.4452 - Test Acc: 10.09%\nEpoch 7/10 - Training Loss: 1.8526 - Training Acc: 25.00% - Validation Loss: 2.8053 - Validation Acc: 0.00%\nTest Loss: 2.5379 - Test Acc: 10.09%\nEpoch 8/10 - Training Loss: 1.7780 - Training Acc: 25.00% - Validation Loss: 2.9881 - Validation Acc: 0.00%\nTest Loss: 2.6490 - Test Acc: 10.09%\nEpoch 9/10 - Training Loss: 1.7040 - Training Acc: 25.00% - Validation Loss: 3.1837 - Validation Acc: 0.00%\nTest Loss: 2.7689 - Test Acc: 10.09%\nEpoch 10/10 - Training Loss: 1.6349 - Training Acc: 25.00% - Validation Loss: 3.3607 - Validation Acc: 0.00%\nTest Loss: 2.8793 - Test Acc: 15.59%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"新数据集的训练和测试","metadata":{}},{"cell_type":"code","source":"# 导入数据\ntrain_datas, val_datas = random_split (new_train_dataset,[10000,len(new_train_dataset)-10000], \n                                       generator=generator)\ntrain_loader = DataLoader(train_datas, batch_size= 64, shuffle=True, num_workers=8, \n                          persistent_workers=True)\nval_loader = DataLoader(val_datas, batch_size= 64, shuffle=False)\ntest_loader = DataLoader(mnist_test, batch_size= 64, shuffle=False)\nmodel = CNN()\n\n# \noptimizer = optim.Adam(model.parameters(), lr=0.003)\ncriterion = nn.CrossEntropyLoss()\n\n# 训练模型\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ntotal_epochs = 40\n\nfor epoch in range(total_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    images, labels = images.to(device), labels.to(device)\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        labels = labels.long()\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    train_loss = running_loss / len(train_loader)\n    train_acc = 100.0 * correct / total\n\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            labels = labels.long()\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    val_loss /= len(val_loader)\n    val_acc = 100.0 * correct / total\n\n    print(f'Epoch {epoch+1}/{total_epochs} - Training Loss: {train_loss:.4f} - Training Acc: {train_acc:.2f}% - '\n          f'Validation Loss: {val_loss:.4f} - Validation Acc: {val_acc:.2f}%')\n    \n\n    # 在测试集上评估模型\n    model.eval()\n    test_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            test_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    test_loss /= len(test_loader)\n    test_acc = 100.0 * correct / total\n\n    print(f'Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.2f}%')","metadata":{"execution":{"iopub.status.busy":"2023-06-29T13:58:29.749276Z","iopub.execute_input":"2023-06-29T13:58:29.749908Z","iopub.status.idle":"2023-06-29T14:00:06.031388Z","shell.execute_reply.started":"2023-06-29T13:58:29.749864Z","shell.execute_reply":"2023-06-29T14:00:06.029665Z"},"trusted":true},"execution_count":115,"outputs":[{"name":"stdout","text":"Epoch 1/40 - Training Loss: 0.4600 - Training Acc: 85.08% - Validation Loss: 0.1519 - Validation Acc: 95.47%\nTest Loss: 0.1771 - Test Acc: 94.33%\nEpoch 2/40 - Training Loss: 0.1126 - Training Acc: 96.74% - Validation Loss: 0.0973 - Validation Acc: 97.06%\nTest Loss: 0.1006 - Test Acc: 96.83%\nEpoch 3/40 - Training Loss: 0.0682 - Training Acc: 97.95% - Validation Loss: 0.0796 - Validation Acc: 97.73%\nTest Loss: 0.0910 - Test Acc: 96.96%\nEpoch 4/40 - Training Loss: 0.0524 - Training Acc: 98.50% - Validation Loss: 0.0783 - Validation Acc: 97.61%\nTest Loss: 0.0831 - Test Acc: 97.18%\nEpoch 5/40 - Training Loss: 0.0377 - Training Acc: 98.83% - Validation Loss: 0.0630 - Validation Acc: 98.28%\nTest Loss: 0.0675 - Test Acc: 97.76%\nEpoch 6/40 - Training Loss: 0.0289 - Training Acc: 99.18% - Validation Loss: 0.0588 - Validation Acc: 98.21%\nTest Loss: 0.0622 - Test Acc: 97.95%\nEpoch 7/40 - Training Loss: 0.0252 - Training Acc: 99.15% - Validation Loss: 0.0729 - Validation Acc: 97.95%\nTest Loss: 0.0771 - Test Acc: 97.66%\nEpoch 8/40 - Training Loss: 0.0175 - Training Acc: 99.36% - Validation Loss: 0.0776 - Validation Acc: 98.09%\nTest Loss: 0.0816 - Test Acc: 97.74%\nEpoch 9/40 - Training Loss: 0.0129 - Training Acc: 99.60% - Validation Loss: 0.0756 - Validation Acc: 98.14%\nTest Loss: 0.0819 - Test Acc: 97.84%\nEpoch 10/40 - Training Loss: 0.0078 - Training Acc: 99.75% - Validation Loss: 0.0860 - Validation Acc: 98.09%\nTest Loss: 0.1013 - Test Acc: 97.39%\nEpoch 11/40 - Training Loss: 0.0136 - Training Acc: 99.52% - Validation Loss: 0.0782 - Validation Acc: 98.13%\nTest Loss: 0.0914 - Test Acc: 97.73%\nEpoch 12/40 - Training Loss: 0.0112 - Training Acc: 99.61% - Validation Loss: 0.0771 - Validation Acc: 98.21%\nTest Loss: 0.0830 - Test Acc: 97.91%\nEpoch 13/40 - Training Loss: 0.0046 - Training Acc: 99.88% - Validation Loss: 0.0845 - Validation Acc: 98.20%\nTest Loss: 0.0878 - Test Acc: 98.09%\nEpoch 14/40 - Training Loss: 0.0081 - Training Acc: 99.75% - Validation Loss: 0.0867 - Validation Acc: 98.06%\nTest Loss: 0.0951 - Test Acc: 97.82%\nEpoch 15/40 - Training Loss: 0.0122 - Training Acc: 99.61% - Validation Loss: 0.0993 - Validation Acc: 97.93%\nTest Loss: 0.0996 - Test Acc: 97.75%\nEpoch 16/40 - Training Loss: 0.0133 - Training Acc: 99.59% - Validation Loss: 0.0862 - Validation Acc: 98.12%\nTest Loss: 0.0971 - Test Acc: 97.65%\nEpoch 17/40 - Training Loss: 0.0067 - Training Acc: 99.76% - Validation Loss: 0.0895 - Validation Acc: 98.33%\nTest Loss: 0.0973 - Test Acc: 97.90%\nEpoch 18/40 - Training Loss: 0.0071 - Training Acc: 99.74% - Validation Loss: 0.0843 - Validation Acc: 98.39%\nTest Loss: 0.0950 - Test Acc: 97.96%\nEpoch 19/40 - Training Loss: 0.0152 - Training Acc: 99.46% - Validation Loss: 0.1292 - Validation Acc: 97.32%\nTest Loss: 0.1413 - Test Acc: 96.76%\nEpoch 20/40 - Training Loss: 0.0096 - Training Acc: 99.70% - Validation Loss: 0.0993 - Validation Acc: 98.06%\nTest Loss: 0.1020 - Test Acc: 97.78%\nEpoch 21/40 - Training Loss: 0.0139 - Training Acc: 99.57% - Validation Loss: 0.0876 - Validation Acc: 98.21%\nTest Loss: 0.1015 - Test Acc: 97.88%\nEpoch 22/40 - Training Loss: 0.0090 - Training Acc: 99.74% - Validation Loss: 0.0990 - Validation Acc: 98.04%\nTest Loss: 0.1078 - Test Acc: 97.69%\nEpoch 23/40 - Training Loss: 0.0097 - Training Acc: 99.69% - Validation Loss: 0.1159 - Validation Acc: 97.63%\nTest Loss: 0.1365 - Test Acc: 97.24%\nEpoch 24/40 - Training Loss: 0.0101 - Training Acc: 99.69% - Validation Loss: 0.1105 - Validation Acc: 97.96%\nTest Loss: 0.1087 - Test Acc: 97.83%\nEpoch 25/40 - Training Loss: 0.0046 - Training Acc: 99.87% - Validation Loss: 0.0963 - Validation Acc: 98.40%\nTest Loss: 0.0951 - Test Acc: 98.28%\nEpoch 26/40 - Training Loss: 0.0014 - Training Acc: 99.93% - Validation Loss: 0.0969 - Validation Acc: 98.51%\nTest Loss: 0.0950 - Test Acc: 98.34%\nEpoch 27/40 - Training Loss: 0.0002 - Training Acc: 100.00% - Validation Loss: 0.0983 - Validation Acc: 98.49%\nTest Loss: 0.0992 - Test Acc: 98.29%\nEpoch 28/40 - Training Loss: 0.0001 - Training Acc: 100.00% - Validation Loss: 0.1002 - Validation Acc: 98.47%\nTest Loss: 0.0950 - Test Acc: 98.41%\nEpoch 29/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1006 - Validation Acc: 98.48%\nTest Loss: 0.0955 - Test Acc: 98.43%\nEpoch 30/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1010 - Validation Acc: 98.50%\nTest Loss: 0.0960 - Test Acc: 98.43%\nEpoch 31/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1014 - Validation Acc: 98.51%\nTest Loss: 0.0965 - Test Acc: 98.43%\nEpoch 32/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1019 - Validation Acc: 98.51%\nTest Loss: 0.0969 - Test Acc: 98.44%\nEpoch 33/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1023 - Validation Acc: 98.53%\nTest Loss: 0.0974 - Test Acc: 98.44%\nEpoch 34/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1027 - Validation Acc: 98.53%\nTest Loss: 0.0978 - Test Acc: 98.44%\nEpoch 35/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1031 - Validation Acc: 98.55%\nTest Loss: 0.0983 - Test Acc: 98.42%\nEpoch 36/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1036 - Validation Acc: 98.54%\nTest Loss: 0.0987 - Test Acc: 98.43%\nEpoch 37/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1040 - Validation Acc: 98.55%\nTest Loss: 0.0992 - Test Acc: 98.43%\nEpoch 38/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1044 - Validation Acc: 98.56%\nTest Loss: 0.0996 - Test Acc: 98.42%\nEpoch 39/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1048 - Validation Acc: 98.56%\nTest Loss: 0.1001 - Test Acc: 98.43%\nEpoch 40/40 - Training Loss: 0.0000 - Training Acc: 100.00% - Validation Loss: 0.1052 - Validation Acc: 98.56%\nTest Loss: 0.1005 - Test Acc: 98.42%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}}]}